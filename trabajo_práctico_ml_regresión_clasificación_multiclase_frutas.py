# -*- coding: utf-8 -*-
"""Grupo 3"""
"""Trabajo Práctico ML - Regresión - Clasificación Multiclase - Frutas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pNtpHK8DSNzQMbwMJvhT3Hs-KJqmksD4

# Trabajo Práctico ML - Regresión Logística - Clasificación Multiclase - Frutas
---

Este dataset lo obtuvimos del siguiente sitio: https://www.muratkoklu.com/datasets/

Clasificación de frutos de dátiles en variedades genéticas.
En todo el mundo se cultiva una gran cantidad de frutas, cada una de las cuales tiene varios tipos. Los factores que determinan el tipo de fruto son las características de la apariencia externa como el color, la longitud, el diámetro y la forma. La apariencia externa de los frutos es un determinante importante del tipo de fruto. Determinar la variedad de frutas observando su apariencia externa puede requerir experiencia, lo que lleva mucho tiempo y requiere un gran esfuerzo. El objetivo de este estudio es clasificar los tipos de dátiles, es decir, Barhee, Deglet Nour, Sukkary, Rotab Mozafati, Ruthana, Safawi y Sagai, utilizando tres métodos diferentes de aprendizaje automático. Se extrajeron un total de 34 características, incluidas características morfológicas, forma y color.

# Contenido Teórico y Práctico para Desarrollo del Trabajo Práctico

**Importación Librerías**
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# LINK SKLEARN LOGISTIC REGRESSION: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html

"""**Carga Dataset**"""

dataset = pd.read_csv('04_Fruit_Datasets.csv')

"""**Análisis Dataset**"""

print('FRUITS DATASET - HEAD: \n', dataset.head(5))

print('FRUITS DATASET - SHAPE: ', dataset.shape)

print('FRUITS DATASET - INFO: \n', dataset.info())

print('FRUITS DATASET - STATISTICS: \n', dataset.describe())

print('FRUITS DATASET - CANTIDAD DE INSTANCIAS POR CLASE: \n', dataset.Class.value_counts())

"""**Preprocesamiento de Datos**"""

# Numerizamos valores en cadena de texto a valor numérico.
# Acomodamos valores de features para facilitar su operatoria.
classes = {'BERHI': 0, 'IRAQI': 1, 'SOGAY': 2, 'DEGLET': 3, 'ROTANA': 4, 'SAFAVI': 5, 'DOKOL': 6}

# Reemplazamos descripciones de feature por su correspondiente valor numérico.
dataset.Class = [classes[item] for item in dataset.Class]
print('FRUITS DATASET - CLASS FEATURE NUMERIZED: \n', dataset)

print('FRUITS DATASET - CANTIDAD DE INSTANCIAS POR CLASE: \n', dataset.Class.value_counts())

classes = dataset.Class.values
unique, counts = np.unique(classes, return_counts=True)

plt.bar(unique,counts)
plt.title('Class Frequency')
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.show()

"""**Análisis Datos**

Coeficientes Correlación (Ver referencia: [correlation matrix](https://www.geeksforgeeks.org/create-a-correlation-matrix-using-python/))
Un coeficiente de correlación (normalmente denominado r) es un número único que describe el alcance de la relación lineal entre dos variables. Un valor de +1 indica una linealidad perfecta (las dos variables se mueven juntas, como "altura en pulgadas" y "altura en centímetros"). Un valor de r = 0 indica que no hay correlación (las variables son independientes) y r = -1 indica que las variables están inversamente correlacionadas (un aumento en una variable se asocia con una disminución en la otra).
"""

cormat = dataset.corr()
print('FRUITS DATASET - CORRELATION MATRIX: \n', round(cormat,2))
sns.heatmap(cormat);

# Como primer análisis, seleccionamos aquellas features que tienen un valor de correlación cercano a 1.
sns.pairplot(dataset[[
 'AREA',
 'PERIMETER',
 'MAJOR_AXIS',
 'MINOR_AXIS',
 'EQDIASQ',
 'CONVEX_AREA',
 'EXTENT'
 ]]);

"""Otra técnica utilizada para identificar relación entre features para seleccionar las más relevantes podemos investigar [mutual_info de scikit learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression) y [ejemplo](https://guhanesvar.medium.com/feature-selection-based-on-mutual-information-gain-for-classification-and-regression-d0f86ea5262a)"""

x_features = dataset.drop(labels=['Class'], axis=1)
x_features

y_features = dataset['Class']
y_features

x_train_mutual_info, x_test_mutual_info, y_train_mutual_info, y_test_mutual_info = train_test_split(x_features, y_features, test_size=0.2, random_state=0, shuffle=True)

from sklearn.feature_selection import mutual_info_regression
mutual_info = mutual_info_regression(x_train_mutual_info, y_train_mutual_info)
print('FRUITS DATASET - MUTUAL INFO: \n', mutual_info)

mutual_info = pd.Series(mutual_info)
mutual_info.index = x_train_mutual_info.columns
mutual_info.sort_values(ascending=False)

mutual_info.sort_values(ascending=False).plot.bar(figsize=(15,5))

"""**Determinación Features Cols**"""

# Determinamos las features que vamos a utilizar para analizar y operar.
feature_cols = [
 'MINOR_AXIS',
'SHAPEFACTOR_1',
'AREA',
'EQDIASQ',
'CONVEX_AREA',
'PERIMETER',
'EntropyRR',
'MAJOR_AXIS']

# Como primer análisis para mutual_info, seleccionamos aquellas features con un valor mayor 0.75
sns.pairplot(dataset[feature_cols]);

x = dataset[feature_cols]
print('FRUITS DATASET - X: \n', x)
y = dataset.Class
print('FRUITS DATASET - Y: \n', y)

"""**Separación Set de Datos**"""

set_test_size = 0.2

# Obtenemoslos set de datos de entrenamiento y pruebas.
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=set_test_size, random_state=0, shuffle=True)

x_train = x_train.values

x_train

y_train = y_train.values

y_train

x_test = x_test.values

x_test

y_test = y_test.values

y_test

"""**Definición Modelo**"""

regressor = LogisticRegression()

"""**Entrenamiento Modelo**"""

regressor.fit(x_train, y_train)

"""**Predicción Resultados**"""

y_pred = regressor.predict(x_test)

print('FRUITS DATASET - Y PREDICTIONS: \n', y_pred)

"""**Evaluación Modelo**"""

cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
print('FRUITS DATASET - CONFUSION MATRIX: \n', cnf_matrix)

# Visualizamos matriz de confusión.
class_names = [0, 1, 2, 3, 4, 5, 6]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap='Blues_r', fmt='g')
ax.xaxis.set_label_position('top')
plt.tight_layout()
plt.title('Confusion Matrix', y=1.1)
plt.ylabel('Current Label')
plt.xlabel('Predicted Label')

# Ejecutamos Reporte de Clasificación.
from sklearn.metrics import classification_report

print('FRUITS DATASET - CLASSIFICATION REPORT: \n', classification_report(y_test, y_pred))

# Evaluamos Score.
print('FRUITS DATASET - ACCURACY SCORE BY METRICS: ', metrics.accuracy_score(y_test, y_pred))

print('FRUITS DATASET - SCORE BY REGRESSOR SCORE: ', regressor.score(x_test, y_test))